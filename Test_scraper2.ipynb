{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3d972e-b162-439d-bdf3-d083df9f4474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e5f08d-d779-4b15-8517-c7867392210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateUrl(query):\n",
    "    query = query.replace(' ', '+')\n",
    "    # Generate Amazon URL from query\n",
    "    url1 = 'https://www.amazon.co.uk/s?k=' + query\n",
    "    \n",
    "    # Generate TechBuyer URL from query\n",
    "    url2 = 'https://www.techbuyer.com/uk/catalogsearch/result/?q=' + query\n",
    "    \n",
    "    # Generate scientific laboratory supplies URL from query\n",
    "    url3 = 'https://www.scientificlabs.co.uk/search/' + query\n",
    "    \n",
    "    # Generate scientific laboratory supplies URL from query\n",
    "    url4 = 'https://www.scientificlabs.co.uk/search/' + query\n",
    "    \n",
    "    return url1, url2, url3\n",
    "\n",
    "def scrapeAmazonProducts(url):\n",
    "    HEADERS = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'}\n",
    "    webpage = requests.get(url, headers=HEADERS)\n",
    "    bs = BeautifulSoup(webpage.content, \"lxml\")\n",
    "    \n",
    "    # Scrape product names\n",
    "    names = bs.findAll('span',{'class':'a-size-medium a-color-base a-text-normal'})\n",
    "    nameList = []\n",
    "    for name in names:\n",
    "        nameList.append(name.get_text())\n",
    "    # Scrape product prices\n",
    "    prices = bs.findAll('span',{'class':'a-offscreen'})\n",
    "    priceList = []\n",
    "    for price in prices:\n",
    "        priceList.append(price.get_text())\n",
    "    # Scrape product urls\n",
    "    urls = bs.findAll('a',{'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
    "    urlList = []\n",
    "    for url in urls:\n",
    "        urlList.append(url.attrs['href'])\n",
    "    \n",
    "    # Store scraped data in a dictionary\n",
    "    n = len(nameList)\n",
    "    products = {}\n",
    "    for i in range(n):\n",
    "        details = {}\n",
    "        details['price'] = priceList[i]\n",
    "        details['url'] = urlList[i]\n",
    "\n",
    "        products[nameList[i]] = details\n",
    "    result['Amazon'] =  products\n",
    "    return result\n",
    "\n",
    "def scrapeTechbuyer(url):\n",
    "    HEADERS = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'}\n",
    "    webpage = requests.get(url, headers=HEADERS)\n",
    "    bs = BeautifulSoup(webpage.content, \"lxml\")\n",
    "    \n",
    "    # Scrape product names\n",
    "    names = bs.findAll('a',{'class':'products__item-link'})\n",
    "    nameList = []\n",
    "    for name in names:\n",
    "        nameList.append(name.get_text())\n",
    "    # Delete the \"\\n\"\n",
    "    temp = []\n",
    "    for n in nameList:\n",
    "        temp.append(n.strip())\n",
    "    nameList = temp\n",
    "    \n",
    "    # Scrape product prices\n",
    "    prices = bs.findAll('span',{'class':'price'})\n",
    "    priceList = []\n",
    "    for price in prices:\n",
    "        priceList.append(price.get_text())\n",
    "    \n",
    "    # Store scraped data in a dictionary\n",
    "    n = len(nameList)\n",
    "    products = {}\n",
    "    for i in range(n):\n",
    "        products[nameList[i]] = priceList[i]\n",
    "    result['Techbuyer'] =  products\n",
    "    return result   \n",
    "\n",
    "def getScientificLabsProduct(bs):\n",
    "    HEADERS = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36'}\n",
    "    webpage = requests.get(url, headers=HEADERS)\n",
    "    bs = BeautifulSoup(webpage.content, \"lxml\")\n",
    "    nameList = []\n",
    "    urlList = []\n",
    "    sizeList = []\n",
    "    priceList = []\n",
    "\n",
    "    # Scrape product details\n",
    "    products = bs.findAll('div', {'class':'table-row'})\n",
    "    for product in products:\n",
    "        name_a = product.find('a',href=True, title=True, style=\"color:black;\", target=True)\n",
    "        href = name_a.get('href')\n",
    "        name = name_a.get('title')\n",
    "        size_div = product.find('div',{'class':'unit-size mobileGridCloserRows flex-100 indentedGridRow mobileDisplayContents range-unit'})\n",
    "        size = size_div.find('span', id=True).get_text()\n",
    "        price = product.find('span',{'class':'gridDisplayBlock'}).get_text()\n",
    "\n",
    "        nameList.append(name)\n",
    "        urlList.append(href)\n",
    "        sizeList.append(size)\n",
    "        priceList.append(price)\n",
    "\n",
    "    n = len(products)\n",
    "    product = {}\n",
    "    for i in range(n):\n",
    "        details = {}\n",
    "        details['size'] = sizeList[i]\n",
    "        details['price'] = priceList[i]\n",
    "        details['url'] = urlList[i]\n",
    "\n",
    "        product[nameList[i]] = details\n",
    "    result['ScientificLaboratorySupplies '] =  product\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba76a7-5126-47ca-bd5b-29dfe76aa83d",
   "metadata": {},
   "source": [
    "# Test for scientific laboratory supplies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d71457a-27eb-4fb6-bc6f-e46f5452c19c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
